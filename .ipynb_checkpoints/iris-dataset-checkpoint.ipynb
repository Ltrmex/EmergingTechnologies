{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset Notebook\n",
    "    A jupyter notebook explaining the famous iris dataset including the difficulty in writing an algorithm to \n",
    "    separate the three classes of iris based on the variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Iris Flower Data Set](#id1)\n",
    "    - [Use of the data set](#id2)\n",
    "    - [Data set](#id3)\n",
    "- [Classification of Iris](#id4)\n",
    "    - [Package Imports](#id5)\n",
    "    - [Load Data](#id6)\n",
    "    - [Inputs](#id7)\n",
    "    - [Encoded outputs](#id8)\n",
    "    - [Idea](#id9)\n",
    "    - [Build model](#id10)\n",
    "    - [Split](#id11)\n",
    "    - [Train](#id12)\n",
    "    - [Predict](#id13)\n",
    "    - [Evaluate](#id14)\n",
    "- [The Iris dataset and pandas](#id15)\n",
    "    - [Pandas](#id16)\n",
    "- [References](#idr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id1\"></a>\n",
    "## Iris Flower Data Set\n",
    "<img src=\"Images/Iris Data.png\" alt=\"Iris Data\" title=\"Iris Flower Data Set\" />\n",
    "- The **Iris flower data set** or Fisher's Iris data set is a **multivariate data set** introduced by the British statistician and biologist **Ronald Fisher** in his 1936 paper The use of multiple measurements in taxonomic problems as an example of **linear discriminant analysis**.\n",
    "-  It is **sometimes called Anderson's Iris data set** because Edgar Anderson collected the data to quantify the morphologic variation of **Iris flowers of three related species**.\n",
    "- The data set **consists of 50 samples** from each of three species of Iris (**Iris setosa**, **Iris virginica** and **Iris versicolor**). \n",
    "- The dataset contains a set of **150 records** under **five attributes** - **petal length**, **petal width**, **sepal length**, **sepal width** and **species**.\n",
    "- **Four features** were measured from each sample: the **length** and the **width** of the **sepals** and **petals**, in centimeters. \n",
    "\n",
    "<a id=\"id2\"></a>\n",
    "### Use of the data set\n",
    "- Based on Fisher's **linear discriminant model**, this data set became a typical test case for many statistical classification techniques in **machine learning** such as **support vector machines**.\n",
    "- One of the **clusters** contains **Iris setosa**, while the other cluster contains both **Iris virginica and Iris versicolor** and is **not separable without the species information** Fisher used.\n",
    "- Fisher's **linear discriminant model** can only be obtained when the **object species are known**: class labels and clusters are not necessarily the same.\n",
    "- Nevertheless, **all three species** of Iris are **separable** in the projection on the **nonlinear branching** principal component. The data set is approximated by the closest tree with some penalty for the excessive number of nodes, bending and stretching. Then the so-called **\"metro map\"** is constructed: \n",
    "<img src=\"Images/Metro Map.png\" alt=\"Metro Map\" title=\"Metro Map\" />\n",
    "__*An example of the so-called \"metro map\" for the Iris data set. Only a small fraction of Iris-virginica is mixed with Iris-versicolor. All other samples of the different Iris species belong to the different nodes.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id3\"></a>\n",
    "### Data set\n",
    "- Based on the **combination of these four features**, Fisher **developed a linear discriminant model** to distinguish the species from each other. \n",
    "\n",
    "| Dataset Order | Sepal Length | Sepal Width | Petal Length | Petal Width |   Species   |\n",
    "| ------------- | ------------ | ----------- | ------------ | ----------- | ----------- |\n",
    "|1|     5.1|    3.5|    1.4|    0.2|    I. setosa|\n",
    "|2|     4.9|    3.0|    1.4|    0.2|    I. setosa|\n",
    "|3| \t4.7| \t3.2| \t1.3| \t0.2| \tI. setosa|\n",
    "|4| \t4.6| \t3.1| \t1.5| \t0.2| \tI. setosa|\n",
    "|5| \t5.0| \t3.6| \t1.4| \t0.3| \tI. setosa|\n",
    "|6| \t5.4| \t3.9|\t1.7| \t0.4| \tI. setosa|\n",
    "|7| \t4.6| \t3.4| \t1.4| \t0.3| \tI. setosa|\n",
    "|8| \t5.0| \t3.4| \t1.5| \t0.2| \tI. setosa|\n",
    "|9| \t4.4| \t2.9| \t1.4| \t0.2| \tI. setosa|\n",
    "|10|    4.9| \t3.1| \t1.5| \t0.1| \tI. setosa|\n",
    "|11|    5.4| \t3.7| \t1.5| \t0.2| \tI. setosa|\n",
    "|12| \t4.8| \t3.4| \t1.6| \t0.2| \tI. setosa|\n",
    "|13| \t4.8| \t3.0| \t1.4| \t0.1| \tI. setosa|\n",
    "|14| \t4.3| \t3.0| \t1.1| \t0.1| \tI. setosa|\n",
    "|15| \t5.8| \t4.0| \t1.2| \t0.2| \tI. setosa|\n",
    "|16| \t5.7| \t4.4| \t1.5| \t0.4| \tI. setosa|\n",
    "|17| \t5.4| \t3.9| \t1.3| \t0.4| \tI. setosa|\n",
    "|18| \t5.1| \t3.5| \t1.4| \t0.3| \tI. setosa|\n",
    "|19| \t5.7| \t3.8| \t1.7| \t0.3| \tI. setosa|\n",
    "|20| \t5.1| \t3.8| \t1.5| \t0.3| \tI. setosa|\n",
    "|21| \t5.4| \t3.4|\t1.7| \t0.2| \tI. setosa|\n",
    "|22| \t5.1| \t3.7| \t1.5| \t0.4| \tI. setosa|\n",
    "|23| \t4.6| \t3.6| \t1.0| \t0.2| \tI. setosa|\n",
    "|24| \t5.1| \t3.3| \t1.7| \t0.5| \tI. setosa|\n",
    "|25| \t4.8| \t3.4| \t1.9| \t0.2| \tI. setosa|\n",
    "|26| \t5.0| \t3.0| \t1.6| \t0.2| \tI. setosa|\n",
    "|27| \t5.0| \t3.4| \t1.6| \t0.4| \tI. setosa|\n",
    "|28| \t5.2| \t3.5| \t1.5| \t0.2| \tI. setosa|\n",
    "|29| \t5.2| \t3.4| \t1.4| \t0.2| \tI. setosa|\n",
    "|30| \t4.7| \t3.2| \t1.6| \t0.2| \tI. setosa|\n",
    "|31| \t4.8| \t3.1| \t1.6| \t0.2| \tI. setosa|\n",
    "|32| \t5.4| \t3.4| \t1.5| \t0.4| \tI. setosa|\n",
    "|33| \t5.2| \t4.1| \t1.5| \t0.1| \tI. setosa|\n",
    "|34| \t5.5| \t4.2| \t1.4| \t0.2| \tI. setosa|\n",
    "|35| \t4.9| \t3.1| \t1.5| \t0.2| \tI. setosa|\n",
    "|36| \t5.0| \t3.2| \t1.2| \t0.2| \tI. setosa|\n",
    "|37| \t5.5| \t3.5| \t1.3| \t0.2| \tI. setosa|\n",
    "|38| \t4.9| \t3.6| \t1.4| \t0.1| \tI. setosa|\n",
    "|39| \t4.4| \t3.0| \t1.3| \t0.2| \tI. setosa|\n",
    "|40| \t5.1| \t3.4| \t1.5| \t0.2| \tI. setosa|\n",
    "|41| \t5.0| \t3.5| \t1.3| \t0.3| \tI. setosa|\n",
    "|42| \t4.5| \t2.3| \t1.3| \t0.3| \tI. setosa|\n",
    "|43| \t4.4| \t3.2| \t1.3| \t0.2| \tI. setosa|\n",
    "|44| \t5.0| \t3.5| \t1.6| \t0.6| \tI. setosa|\n",
    "|45| \t5.1| \t3.8| \t1.9| \t0.4| \tI. setosa|\n",
    "|46| \t4.8| \t3.0| \t1.4| \t0.3| \tI. setosa|\n",
    "|47| \t5.1| \t3.8| \t1.6| \t0.2| \tI. setosa|\n",
    "|48| \t4.6| \t3.2| \t1.4| \t0.2| \tI. setosa|\n",
    "|49| \t5.3| \t3.7| \t1.5| \t0.2| \tI. setosa|\n",
    "|50| \t5.0| \t3.3| \t1.4| \t0.2| \tI. setosa|\n",
    "|51| \t7.0| \t3.2| \t4.7| \t1.4| \tI. versicolor|\n",
    "|52| \t6.4| \t3.2| \t4.5| \t1.5| \tI. versicolor|\n",
    "|53| \t6.9| \t3.1| \t4.9| \t1.5| \tI. versicolor|\n",
    "|54| \t5.5| \t2.3| \t4.0| \t1.3| \tI. versicolor|\n",
    "|55| \t6.5| \t2.8| \t4.6| \t1.5| \tI. versicolor|\n",
    "|56| \t5.7| \t2.8| \t4.5| \t1.3| \tI. versicolor|\n",
    "|57| \t6.3| \t3.3| \t4.7| \t1.6| \tI. versicolor|\n",
    "|58| \t4.9| \t2.4| \t3.3| \t1.0| \tI. versicolor|\n",
    "|59| \t6.6| \t2.9| \t4.6| \t1.3| \tI. versicolor|\n",
    "|60| \t5.2| \t2.7| \t3.9| \t1.4| \tI. versicolor|\n",
    "|61| \t5.0| \t2.0| \t3.5| \t1.0| \tI. versicolor|\n",
    "|62| \t5.9| \t3.0| \t4.2| \t1.5| \tI. versicolor|\n",
    "|63| \t6.0| \t2.2| \t4.0| \t1.0| \tI. versicolor|\n",
    "|64| \t6.1| \t2.9| \t4.7| \t1.4| \tI. versicolor|\n",
    "|65| \t5.6| \t2.9| \t3.6| \t1.3| \tI. versicolor|\n",
    "|66| \t6.7| \t3.1| \t4.4| \t1.4| \tI. versicolor|\n",
    "|67| \t5.6| \t3.0| \t4.5| \t1.5| \tI. versicolor|\n",
    "|68| \t5.8| \t2.7| \t4.1| \t1.0| \tI. versicolor|\n",
    "|69| \t6.2| \t2.2| \t4.5| \t1.5| \tI. versicolor|\n",
    "|70| \t5.6| \t2.5| \t3.9| \t1.1| \tI. versicolor|\n",
    "|71| \t5.9| \t3.2| \t4.8| \t1.8| \tI. versicolor|\n",
    "|72| \t6.1| \t2.8| \t4.0| \t1.3| \tI. versicolor|\n",
    "|73| \t6.3| \t2.5| \t4.9| \t1.5| \tI. versicolor|\n",
    "|74| \t6.1| \t2.8| \t4.7| \t1.2| \tI. versicolor|\n",
    "|75| \t6.4| \t2.9| \t4.3| \t1.3| \tI. versicolor|\n",
    "|76| \t6.6| \t3.0| \t4.4| \t1.4| \tI. versicolor|\n",
    "|77| \t6.8| \t2.8| \t4.8| \t1.4| \tI. versicolor|\n",
    "|78| \t6.7| \t3.0| \t5.0| \t1.7| \tI. versicolor|\n",
    "|79| \t6.0| \t2.9| \t4.5| \t1.5| \tI. versicolor|\n",
    "|80| \t5.7| \t2.6| \t3.5| \t1.0| \tI. versicolor|\n",
    "|81| \t5.5| \t2.4| \t3.8| \t1.1| \tI. versicolor|\n",
    "|82| \t5.5| \t2.4| \t3.7| \t1.0| \tI. versicolor|\n",
    "|83| \t5.8| \t2.7| \t3.9| \t1.2| \tI. versicolor|\n",
    "|84| \t6.0| \t2.7| \t5.1| \t1.6| \tI. versicolor|\n",
    "|85| \t5.4| \t3.0| \t4.5| \t1.5| \tI. versicolor|\n",
    "|86| \t6.0| \t3.4| \t4.5| \t1.6| \tI. versicolor|\n",
    "|87| \t6.7| \t3.1| \t4.7| \t1.5| \tI. versicolor|\n",
    "|88| \t6.3| \t2.3| \t4.4| \t1.3| \tI. versicolor|\n",
    "|89| \t5.6| \t3.0| \t4.1| \t1.3| \tI. versicolor|\n",
    "|90| \t5.5| \t2.5| \t4.0| \t1.3| \tI. versicolor|\n",
    "|91| \t5.5| \t2.6| \t4.4| \t1.2| \tI. versicolor|\n",
    "|92| \t6.1| \t3.0| \t4.6| \t1.4| \tI. versicolor|\n",
    "|93| \t5.8| \t2.6| \t4.0| \t1.2| \tI. versicolor|\n",
    "|94| \t5.0| \t2.3| \t3.3| \t1.0| \tI. versicolor|\n",
    "|95| \t5.6| \t2.7| \t4.2| \t1.3| \tI. versicolor|\n",
    "|96| \t5.7| \t3.0| \t4.2| \t1.2| \tI. versicolor|\n",
    "|97| \t5.7| \t2.9| \t4.2| \t1.3| \tI. versicolor|\n",
    "|98| \t6.2| \t2.9| \t4.3| \t1.3| \tI. versicolor|\n",
    "|99| \t5.1| \t2.5| \t3.0| \t1.1| \tI. versicolor|\n",
    "|100| \t5.7| \t2.8| \t4.1| \t1.3| \tI. versicolor|\n",
    "|101| \t6.3| \t3.3| \t6.0| \t2.5| \tI. virginica|\n",
    "|102| \t5.8| \t2.7| \t5.1| \t1.9| \tI. virginica|\n",
    "|103| \t7.1| \t3.0| \t5.9| \t2.1| \tI. virginica|\n",
    "|104| \t6.3| \t2.9| \t5.6| \t1.8| \tI. virginica|\n",
    "|105| \t6.5| \t3.0| \t5.8| \t2.2| \tI. virginica|\n",
    "|106| \t7.6| \t3.0| \t6.6| \t2.1| \tI. virginica|\n",
    "|107| \t4.9| \t2.5| \t4.5| \t1.7| \tI. virginica|\n",
    "|108| \t7.3| \t2.9| \t6.3| \t1.8| \tI. virginica|\n",
    "|109| \t6.7| \t2.5| \t5.8| \t1.8| \tI. virginica|\n",
    "|110| \t7.2| \t3.6| \t6.1| \t2.5| \tI. virginica|\n",
    "|111| \t6.5| \t3.2| \t5.1| \t2.0| \tI. virginica|\n",
    "|112| \t6.4| \t2.7| \t5.3| \t1.9| \tI. virginica|\n",
    "|113| \t6.8| \t3.0| \t5.5| \t2.1| \tI. virginica|\n",
    "|114| \t5.7| \t2.5| \t5.0| \t2.0| \tI. virginica|\n",
    "|115| \t5.8| \t2.8| \t5.1| \t2.4| \tI. virginica|\n",
    "|116| \t6.4| \t3.2| \t5.3| \t2.3| \tI. virginica|\n",
    "|117| \t6.5| \t3.0| \t5.5| \t1.8| \tI. virginica|\n",
    "|118| \t7.7| \t3.8| \t6.7| \t2.2| \tI. virginica|\n",
    "|119| \t7.7| \t2.6|\t6.9| \t2.3| \tI. virginica|\n",
    "|120| \t6.0| \t2.2| \t5.0| \t1.5| \tI. virginica|\n",
    "|121| \t6.9| \t3.2| \t5.7| \t2.3| \tI. virginica|\n",
    "|122| \t5.6| \t2.8| \t4.9| \t2.0| \tI. virginica|\n",
    "|123| \t7.7| \t2.8| \t6.7| \t2.0| \tI. virginica|\n",
    "|124| \t6.3| \t2.7| \t4.9| \t1.8| \tI. virginica|\n",
    "|125| \t6.7| \t3.3| \t5.7| \t2.1| \tI. virginica|\n",
    "|126| \t7.2| \t3.2| \t6.0| \t1.8| \tI. virginica|\n",
    "|127| \t6.2| \t2.8| \t4.8| \t1.8| \tI. virginica|\n",
    "|128| \t6.1| \t3.0| \t4.9| \t1.8| \tI. virginica|\n",
    "|129| \t6.4| \t2.8| \t5.6| \t2.1| \tI. virginica|\n",
    "|130| \t7.2| \t3.0| \t5.8| \t1.6| \tI. virginica|\n",
    "|131| \t7.4| \t2.8|\t6.1| \t1.9| \tI. virginica|\n",
    "|132| \t7.9| \t3.8| \t6.4|\t2.0| \tI. virginica|\n",
    "|133| \t6.4| \t2.8| \t5.6| \t2.2| \tI. virginica|\n",
    "|134| \t6.3| \t2.8| \t5.1| \t1.5| \tI. virginica|\n",
    "|135| \t6.1| \t2.6| \t5.6| \t1.4| \tI. virginica|\n",
    "|136| \t7.7| \t3.0| \t6.1| \t2.3| \tI. virginica|\n",
    "|137| \t6.3| \t3.4| \t5.6| \t2.4| \tI. virginica|\n",
    "|138| \t6.4| \t3.1| \t5.5| \t1.8| \tI. virginica|\n",
    "|139| \t6.0| \t3.0| \t4.8| \t1.8| \tI. virginica|\n",
    "|140| \t6.9| \t3.1| \t5.4| \t2.1| \tI. virginica|\n",
    "|141| \t6.7| \t3.1| \t5.6| \t2.4| \tI. virginica|\n",
    "|142| \t6.9| \t3.1| \t5.1| \t2.3| \tI. virginica|\n",
    "|143| \t5.8| \t2.7| \t5.1| \t1.9| \tI. virginica|\n",
    "|144| \t6.8| \t3.2| \t5.9| \t2.3| \tI. virginica|\n",
    "|145| \t6.7| \t3.3| \t5.7| \t2.5| \tI. virginica|\n",
    "|146| \t6.7| \t3.0| \t5.2| \t2.3| \tI. virginica|\n",
    "|147| \t6.3| \t2.5| \t5.0| \t1.9| \tI. virginica|\n",
    "|148| \t6.5| \t3.0| \t5.2| \t2.0| \tI. virginica|\n",
    "|149| \t6.2| \t3.4| \t5.4| \t2.3| \tI. virginica|\n",
    "|150| \t5.9| \t3.0| \t5.1| \t1.8| \tI. virginica|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id4\"></a>\n",
    "## Classification of Iris\n",
    "<a id=\"id5\"></a>\n",
    "### Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For building neural networks.\n",
    "import keras as kr\n",
    "\n",
    "# For interacting with data sets.\n",
    "import pandas as pd\n",
    "\n",
    "# For encoding categorical variables.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "# For splitting into training and test sets.\n",
    "import sklearn.model_selection as mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id6\"></a>\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris data set from a URL.\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id7\"></a>\n",
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the inputs from the rest of the variables.\n",
    "inputs = df[['petal_length', 'petal_width', 'sepal_length', 'sepal_width']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id8\"></a>\n",
    "### Encoded outputs\n",
    "$$ setosa \\rightarrow [1,0,0] $$\n",
    "$$ versicolor \\rightarrow [0,1,0] $$\n",
    "$$ virginica \\rightarrow [0,0,1] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the classes as above.\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(df['species'])\n",
    "outputs = encoder.transform(df['species'])\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id9\"></a>\n",
    "### Idea\n",
    "- The neural network will turn four floating point inputs into three \"floating point\" outputs.\n",
    "$$ [5.1, 3.5, 1.4, 0.2] \\rightarrow [1, 0, 0] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id10\"></a>\n",
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 64 neurons and an input layer with 4.\n",
    "model.add(kr.layers.Dense(units=64, activation='relu', input_dim=4))\n",
    "# Add a three neuron output layer.\n",
    "model.add(kr.layers.Dense(units=3, activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id11\"></a>\n",
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the inputs and outputs into training and test sets.\n",
    "inputs_train, inputs_test, outputs_train, outputs_test = mod.train_test_split(inputs, outputs, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id12\"></a>\n",
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.9585 - acc: 0.5067\n",
      "Epoch 2/15\n",
      "75/75 [==============================] - 0s 0us/step - loss: 0.7493 - acc: 0.7333\n",
      "Epoch 3/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.6573 - acc: 0.7600\n",
      "Epoch 4/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.6359 - acc: 0.7600\n",
      "Epoch 5/15\n",
      "75/75 [==============================] - 0s 0us/step - loss: 0.5847 - acc: 0.7467\n",
      "Epoch 6/15\n",
      "75/75 [==============================] - 0s 294us/step - loss: 0.5636 - acc: 0.7867\n",
      "Epoch 7/15\n",
      "75/75 [==============================] - 0s 0us/step - loss: 0.5387 - acc: 0.7600\n",
      "Epoch 8/15\n",
      "75/75 [==============================] - 0s 0us/step - loss: 0.5322 - acc: 0.7467\n",
      "Epoch 9/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.5191 - acc: 0.7467\n",
      "Epoch 10/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.4927 - acc: 0.8000\n",
      "Epoch 11/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.4718 - acc: 0.7867\n",
      "Epoch 12/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.4587 - acc: 0.8800\n",
      "Epoch 13/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.4495 - acc: 0.7733\n",
      "Epoch 14/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.4244 - acc: 0.8400\n",
      "Epoch 15/15\n",
      "75/75 [==============================] - 0s 208us/step - loss: 0.4206 - acc: 0.8800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x276fe1db7f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the neural network.\n",
    "model.fit(inputs_train, outputs_train, epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id13\"></a>\n",
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'setosa',\n",
       "       'virginica', 'virginica', 'virginica', 'setosa', 'setosa',\n",
       "       'virginica', 'setosa', 'virginica', 'virginica', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'setosa', 'setosa', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'setosa',\n",
       "       'virginica', 'setosa', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica', 'setosa', 'setosa', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'virginica', 'virginica', 'setosa', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'setosa', 'virginica',\n",
       "       'setosa', 'virginica', 'virginica', 'virginica', 'setosa',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have the network predict the classes of the test inputs.\n",
    "predictions = model.predict(inputs_test)\n",
    "predictions = encoder.inverse_transform(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id14\"></a>\n",
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False,  True, False,  True,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False, False,\n",
       "       False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False, False,  True, False,  True,\n",
       "       False,  True,  True,  True, False, False,  True, False, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "        True, False, False])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the predictions to the actual classes.\n",
    "predictions == encoder.inverse_transform(outputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == encoder.inverse_transform(outputs_test)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"id15\"></a>\n",
    "## The Iris dataset and pandas\n",
    "<a id=\"id16\"></a>\n",
    "### Pandas\n",
    "- Python Data Analysis Library\n",
    "- Is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows top of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"idr\"></a>\n",
    "###### References: \n",
    "- __[Iris Flower Data Set](https://en.wikipedia.org/wiki/Iris_flower_data_set)__\n",
    "- __[Markdown](https://medium.com/ibm-data-science-experience/markdown-for-jupyter-notebooks-cheatsheet-386c05aeebed)__\n",
    "- __[Classification of Iris](https://github.com/ianmcloughlin/jupyter-teaching-notebooks/blob/master/keras-and-iris.ipynb)__\n",
    "- __[Clustering: Separating the iris species](https://rstudio-pubs-static.s3.amazonaws.com/133105_57fa702e3f5c49518e8678daf60bc1e0.html)__\n",
    "- __[Case Study: IRIS Classification](http://rstudio-pubs-static.s3.amazonaws.com/269829_8285925c922e445097f47925b112841f.html)__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
